To help us walk through some troubleshooting steps when it comes to Istio, we're going to use a simple demo application. Here's a workflow to show what we should expect from the application. Basically..

1. There will be 3 deployments, a UI, a backend and a Mongo database.
2. When a user accesses the application, they should be redirected to the Keycloak OIDC provider for authentication.
3. After a successful login, the user should be redirected back to the UI. The UI Javascript will make a call the backend deployment API for the user's name and location, which are stored in Mongo.
4. The UI will then display this information in a welcome message.

So let's pull up a browser and give the demo application a shot.

-------------
WRONG GATEWAY
-------------

When I go to the URL for the app, I'm getting a 404 Not Found response. The first thing I want to do is confirm that this is an issue inside of K8s and Istio. To do that, I'm going to pull up the Javascript Console and check the request for Response Headers.

If a request reached a proxy sidecar, there should be a 'server: envoy' response header. This let's us know the request did get to a sidecar, and there must be an issue internal to K8s, Istio, or our application code. Not an external dependency like DNS.

The tool I'm going to use today to show how you can troubleshoot Istio issues is the istioctl CLI. If you've worked with Istio before, you're probably familiar with it and have used it to install or upgrade istio, but it also provides a lot of powerful troubleshooting capabilities.

The first one of those is 'analyze'. With analyze, istioctl will do an analysis of your istio configurations within a namespace, workload, or files, and print any validation issues it finds along the way. This is my go-to for a first line of defense against Istio issues.

So, I'm going to pull up a terminal and run 'istioctl analyze -n welcome-app'.

You can see there's a few issues. We're going to focus on the first 2 for now. This is saying that the virtual service 'app-ingress' in the namespace 'welcome-app' is referencing the 'istio-ingressgateway' in 'istio-system', which doesn't exist.

So let's first check our gateways. (k get gateways -A)

You can see we only have 2 gateways defined, and for the purpose of this exercise, our virtual service should be referencing 'main'. So I'm going to edit the virtual service and update the gateway reference.. (k edit vs -n welcome-app app-ingress)

Let's check analyze one more time. (istioctl analyze -n welcome-app) You can see the first issues were resolved, and we'll come back to the remaining one.

Now if we go back to the browser and refresh, you can see we're getting to the page, but we're getting a 503 error. 

------------
SERVICE PORT
------------

If we check the next message in our analyze command, you can see that the 'backend' k8s service in the 'welcome-app' namespace has as port defined, 5000, that doesn't adhere to istio naming standards.

Istio naming standards, especially in context of service ports, are very important. They help Istio determine what protocol it should use when it proxies traffic to an application. So we're going to edit our service and make sure that port 5000 has a name field.

I know this service is using HTTP, so I'm just going to add 'name: http' and save the service. Let's run analyze one more time, and now you can see the errors are all cleared up.

Back in our browser, if we refresh, you can see we're now getting a 403 error. So we know our configurations are valid, but with a 403 Forbidden, we're most likely hitting an RBAC issue. We can actually check this by opening the API call in the browser. It's a little obfuscated in the UI, but if we grab it from JS console, you can see it is returning an RBAC error.

-----------
AUTH POLICY
-----------

With the Istioctl CLI tool, it's constantly evolving. More and more features keep getting added, especially when it comes to troubleshooting, and even though some are considered experimental, they're still very powerful. One of those capabilities I'm going to use today is the authz check.

If we come back to terminal and run 'istioctl exp authz check --help', you'll see this command will provide a comprehensive list of all Istio Authorization policies that apply to a specific pod or deployment, whether scoped at the mesh, namespace, or workload. This is great to see exactly how traffic is being managed through your mesh.

So let's run 'istioctl exp authz check -n welcome-app deploy/backend'. You can see there's a single authorizationpolicy, the internal-authpolicy, being applied, and if we take a look at that, it's basically only allowing workloads within the 'welcome-app' namespace to talk to other pods within the 'welcome-app' namespace. Basically only inner-namespace traffic.

Since the browser needs to hit this API, we need it to be a little more exposed than it is now. So I have this backend AuthorizationPolicy set up that will apply to any workloads in the 'welcome-app' namespace that match the 'app: backend' label. It will allow quad-0, or access from anywhere, to any HTTP GET request. So if I apply this (k apply -f backend-authpolicy.yaml), I can come back and re-run my authz check command, and now you see 2 policies are applied.

One other thing I'd like to do is validate the policy isn't applying to workloads it shouldn't be, so I'm going to run the same command against the mongo deployment. You can see it still only has the internal authpolicy applied, which is what we want. We don't want our database exposed to the world.

Great, so now we can go back to our browser and refresh. And you can see we've cleared up all the response code errors and are getting 200 responses, but the application still isn't properly redirecting and authenticating a user.

------------
PROXY-CONFIG
------------

For this, we're going to dig deeper into istioctl and take a look at the proxy configs for our backend deployment. In case you weren't aware, within every sidecar proxy deployed by Istio, a dynamically changing configuration exists that basically tells the proxy and mesh how to route traffic using pattern matches and defined protocols. 

I also do want to do a quick overview of how the auth redirect is working just for a basis of understanding. We have an envoyfilter defined globally in the istio-system namespace called 'authservice'. This filter sits on the default inbound port of the sidecar, 15006, and as requests come in, they will percolate through those filters before reaching the app. This filter will proxy requests to an authservice deployment within the cluster, which is a nice little tool maintained by Tetrate that manages OIDC JWT validation and expiration redirects, as well as add headers containing user profile to the request before forwarding to the app for the app's code to consume.

So, since we're not getting redirected, we need a way to check if our filter is actually being applied to the sidecars. With istioctl, we can take a look at the listener configurations of the proxy on specific ports. In this case, we're going to run 'istioctl proxy-config listener -n welcome-app deploy/backend --port 15006 -o json | less'.

So I'm going to do a quick grep for 'httpFilters' to find all of the HTTP-level envoy filters being applied to inbound requests on this port. Looking through here, I'd expect an ext_authz filter being applied with some authservice parameters. But since I'm not seeing that, clearly there's a misconfiguration between our workloads and the filter.

So, filters use label selectors to determine which workloads they should be applied to. If I run 'k get deploy -n welcome-app --show-labels', you can see the 'auth: enabled' label being applied to the UI and backend deployments. And if we check our envoyfilter and go to the bottom, you can see it is currently set to 'auth: none'. So let's update our filter and save it. Now if we take a look at our proxy-config, we can see that the filter is being applied to this listener port. And if we now go to the browser, and I'm going to close it to avoid caching issues.. Now I go back to my app, you can see we successfully get redirected, and after logging in, we get the welcome message we expected.

So again, these are just a few of the ways to troubleshoot istio, specifically using IstioCtl. There are plenty of other tools out there for both troubleshooting and maintainability. Just to run through a few:

  * Prometheus: Time-series database for storing all mesh-level metrics. It's the lifeblood for the other monitoring tools we're going to talk about.
  * Grafana: A visualization and alerting tools using Prometheus-based metrics. You can set threshold-based alerts on metrics and get notifications through Slack, email, PagerDuty, SMS, etc.
  * Kiali: Real-time graphical representation of your mesh. It provides a "spider-web" way of looking at traffic to quickly identify any issues between specific microservices or mesh entities.
  * Jaeger: Great for fine-grain tracing and traversal of requests through your microservices within your mesh.

One more note about istioctl that I hinted about earlier. It gives you a very simple way to both upgrade your controlplane in place as well as validate your existing installation. These also come with dry-run capabilities to avoid doing something before you're sure of the results.

